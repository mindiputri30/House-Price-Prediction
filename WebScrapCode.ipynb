{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install beautifulsoup4\n",
    "# %pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install urllib3==1.26.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_page_url(base_url, page_number):\n",
    "#     page_url = base_url.replace('/page=1/', f'/page={page_number}/')\n",
    "#     return page_url\n",
    "\n",
    "def generate_page_url(base_url, page_number):\n",
    "    url_parts = base_url.split('=')\n",
    "    url_parts[-1] = str(page_number)\n",
    "    page_url = '='.join(url_parts)\n",
    "    return page_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Link to Detail Page\n",
    "dashboard_url = 'https://www.lamudi.co.id/west-nusa-tenggara/house/buy/?page=1'\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "for page_number in range(1, 21):  # Ubah 20 menjadi 21 untuk memperoleh halaman 1 hingga 20\n",
    "    current_page_url = generate_page_url(dashboard_url, page_number)\n",
    "    driver.get(current_page_url)\n",
    "\n",
    "    # STATIS\n",
    "    # soup = BeautifulSoup(driver.page_source, 'html.parser')  # Menggunakan driver.page_source untuk konten halaman\n",
    "    # links = soup.find_all('a', class_='ListingCell-moreInfo-button-v2_redesign')\n",
    "    # for link in links:\n",
    "    #     print(link['href'])\n",
    "\n",
    "    # Tunggu hingga konten dinamis selesai dimuat\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'ListingCell-moreInfo-button-v2_redesign')))\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    links = soup.find_all('a', class_='ListingCell-moreInfo-button-v2_redesign')\n",
    "    \n",
    "    for link in links:\n",
    "        print(link['href'])\n",
    "    \n",
    "    print(len(links))\n",
    "    \n",
    "driver.quit()  # Tutup browser setelah selesai scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "def generate_page_url(base_url, page_number):\n",
    "    page_url = base_url.replace('/page.1/', f'/page.{page_number}/')\n",
    "    return page_url\n",
    "\n",
    "dashboard_url = 'https://rumah.trovit.co.id/index.php/cod.search_adwords_homes/type.1/what_d.Nusa%20Tenggara%20Barat/origin.1/ppc_landing_type.2/rooms_min.0/bathrooms_min.0/property_type.Rumah/region.Nusa Tenggara Barat/order_by.relevance/resultsPerPage.25/isUserSearch.1/page.1'\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    current_page_url = generate_page_url(dashboard_url, page_number)\n",
    "    driver.get(current_page_url)\n",
    "    # WebDriverWait(driver, 10).until(EC.url_to_be(current_page_url))\n",
    "    response = requests.get(dashboard_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        dashboard_content = response.content\n",
    "        dashboard_soup = BeautifulSoup(dashboard_content, 'html.parser')\n",
    "\n",
    "\n",
    "        harga_element = dashboard_soup.find('div', class_='item-price')\n",
    "        harga = harga_element.find('span', class_='actual-price').text.strip()\n",
    "\n",
    "\n",
    "        links = dashboard_soup.find_all('a', class_='rd-link image-link')\n",
    "\n",
    "\n",
    "        data_properti = []\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for link in links:\n",
    "            i += 1\n",
    "            detail_url = link['href']\n",
    "            driver.get(detail_url)\n",
    "            print(\"GO! \", i)\n",
    "            try:\n",
    "                print(\"Menemukan (Menampilkan Lebih Banyak)\")\n",
    "                link_element = driver.find_element(By.CLASS_NAME, 'relative ui-content-half__selector')\n",
    "                driver.execute_script(\"arguments[0].click();\", link_element)\n",
    "                time.sleep(2)  \n",
    "                detail_content = driver.page_source\n",
    "\n",
    "                try: \n",
    "                    iklan_content = driver.find_element(By.CLASS_NAME, 'pinder modal')\n",
    "                    iklan_soup = BeautifulSoup(iklan_content, 'html.parser')\n",
    "                    close_button = iklan_soup.find('button', class_='button_close')\n",
    "                    print(\"ada iklan\")\n",
    "                    if close_button:\n",
    "                        driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    link_element = driver.find_element(By.CLASS_NAME, 'ui-listing-specification__table--row')\n",
    "                    # WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'ui-listing-specification__table--row')))\n",
    "                    detail_content = driver.page_source\n",
    "                    print(\"Menemukan (Row Spek)\")\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "            detail_soup = BeautifulSoup(detail_content, 'html.parser')\n",
    "            lokasi_element = detail_soup.find('div', class_='r123-listing-summary__header-container-address')\n",
    "            lokasi = lokasi_element.text.strip() if lokasi_element else ''\n",
    "            spesifikasi_element = detail_soup.find('div', class_='ui-listing-specification__table')\n",
    "\n",
    "            if spesifikasi_element is None:\n",
    "                continue\n",
    "\n",
    "            rows = spesifikasi_element.find_all('div', class_='ui-listing-specification__table--row')\n",
    "            properti = {}\n",
    "\n",
    "            for row in rows:\n",
    "                label = row.find('p', class_='ui-listing-specification__table--label').text.strip()\n",
    "                value = row.find('p', class_='ui-listing-specification__table--value').text.strip()\n",
    "                properti[label] = value\n",
    "\n",
    "            properti['Harga'] = harga\n",
    "            properti['Lokasi'] = lokasi\n",
    "            data_properti.append(properti)\n",
    "\n",
    "        header = ['K. Tidur', 'K. Mandi', 'L. Tanah', 'L. Bangunan', 'Tipe Properti', 'Sertifikat', 'Daya Listrik', 'ID Iklan', 'Harga', 'Lokasi']\n",
    "        with open('data_properti.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data_properti)\n",
    "\n",
    "        print('Web scraping selesai. Data properti telah disimpan dalam file data_properti.csv')\n",
    "    else:\n",
    "        print('Gagal mengakses halaman dashboard')\n",
    "    \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//p[@class=\"trovit-paginator\"]/a[@class=\"trovit-button no-background next\"]')\n",
    "        if not next_button.is_enabled():\n",
    "            break\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    page_number += 1\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URL halaman dashboard\n",
    "# dashboard_url = 'https://rumah.trovit.co.id/index.php/cod.search_adwords_homes/ppc_landing_type.3/type.1/what_d.Nusa%20Tenggara%20Barat/sug.0/isUserSearch.1/origin.1/order_by.relevance/region.Nusa%20Tenggara%20Barat/property_type.Rumah/'\n",
    "# # Ganti dengan URL halaman dashboardmu\n",
    "\n",
    "# # Mengirim permintaan HTTP ke halaman dashboard\n",
    "# response = requests.get(dashboard_url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     dashboard_content = response.content\n",
    "#     dashboard_soup = BeautifulSoup(dashboard_content, 'html.parser')\n",
    "\n",
    "#     # Mendapatkan harga dari halaman dashboard\n",
    "#     harga_element = dashboard_soup.find('div', class_='item-price')\n",
    "#     harga = harga_element.find('span', class_='actual-price').text.strip()\n",
    "\n",
    "#     # Mendapatkan link detail properti dari halaman dashboard\n",
    "#     links = dashboard_soup.find_all('a', class_='rd-link image-link')\n",
    "\n",
    "#     # Inisialisasi list untuk menyimpan data properti\n",
    "#     data_properti = []\n",
    "\n",
    "#     # Inisialisasi WebDriver Selenium\n",
    "#     driver = webdriver.Chrome()  # Ganti dengan driver sesuai preferensi (misal: Firefox, Safari)\n",
    "\n",
    "#     # Loop melalui setiap link detail properti\n",
    "#     for link in links:\n",
    "#         detail_url = link['href']\n",
    "#         driver.get(detail_url)\n",
    "\n",
    "#         try:\n",
    "#             # Cari elemen teks link dan klik\n",
    "#             # link_element = driver.find_element(By.XPATH, '//div[contains(text(), \"Menampilkan lebih banyak\")]')\n",
    "#             # driver.execute_script(\"arguments[0].click();\", link_element)\n",
    "#             # Cari elemen teks link dan klik\n",
    "\n",
    "#             link_element = driver.find_element(By.CLASS_NAME, 'relative ui-content-half__selector')\n",
    "#             driver.execute_script(\"arguments[0].click();\", link_element)\n",
    "\n",
    "#             # Tunggu beberapa detik\n",
    "#             time.sleep(2)  # Ubah angka 5 menjadi jumlah detik yang Anda anggap perlu\n",
    "\n",
    "#             # Ambil konten HTML setelah modal view muncul\n",
    "#             detail_content = driver.page_source\n",
    "\n",
    "#             # Ada iklan\n",
    "#             iklan_content = driver.find_element(By.CLASS_NAME, 'pinder modal')\n",
    "\n",
    "#             # Setelah Anda mendapatkan konten HTML modal iklan\n",
    "#             iklan_soup = BeautifulSoup(iklan_content, 'html.parser')\n",
    "\n",
    "#             # Cari elemen tombol penutup\n",
    "#             close_button = iklan_soup.find('button', class_='button_close')\n",
    "\n",
    "#             # Jika tombol penutup ditemukan, klik tombol tersebut\n",
    "#             if close_button:\n",
    "#                 driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "\n",
    "\n",
    "#             # Tunggu hingga modal view muncul\n",
    "#             try:\n",
    "#                 WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'ui-listing-specification__table--row')))\n",
    "\n",
    "#                 # link_detil = driver.find_element(By.CLASS_NAME, 'ui-listing-specification__table--row')\n",
    "#                 # Ambil konten HTML setelah modal view muncul\n",
    "#                 detail_content = driver.page_source\n",
    "#             except NoSuchElementException:\n",
    "#                 # Skip data properti jika tidak ditemukan elemen \"Menampilkan lebih banyak\"\n",
    "#                 continue\n",
    "\n",
    "#         except NoSuchElementException:\n",
    "#             # Skip data properti jika tidak ditemukan elemen \"Menampilkan lebih banyak\"\n",
    "#             continue\n",
    "\n",
    "\n",
    "\n",
    "#         # Buat objek BeautifulSoup baru dari konten HTML yang diperoleh\n",
    "#         detail_soup = BeautifulSoup(detail_content, 'html.parser')\n",
    "\n",
    "#         # Mendapatkan lokasi dari halaman detail properti\n",
    "#         lokasi_element = detail_soup.find('div', class_='r123-listing-summary__header-container-address')\n",
    "#         lokasi = lokasi_element.text.strip() if lokasi_element else ''\n",
    "\n",
    "#         # Mendapatkan spesifikasi properti dari halaman detail properti\n",
    "#         # spesifikasi_element = detail_soup.find('div', class_='ui-listing-specification__table')\n",
    "#         # rows = spesifikasi_element.find_all('div', class_='ui-listing-specification__table--row')\n",
    "#         # Mendapatkan spesifikasi properti dari halaman detail properti\n",
    "#         spesifikasi_element = detail_soup.find('div', class_='ui-listing-specification__table')\n",
    "#         if spesifikasi_element is None:\n",
    "#             continue\n",
    "\n",
    "#         rows = spesifikasi_element.find_all('div', class_='ui-listing-specification__table--row')\n",
    "\n",
    "\n",
    "#         # Membuat dictionary untuk menyimpan data spesifikasi properti\n",
    "#         properti = {}\n",
    "\n",
    "#         for row in rows:\n",
    "#             label = row.find('p', class_='ui-listing-specification__table--label').text.strip()\n",
    "#             value = row.find('p', class_='ui-listing-specification__table--value').text.strip()\n",
    "#             properti[label] = value\n",
    "\n",
    "#         # Menambahkan harga dan lokasi ke dictionary properti\n",
    "#         properti['Harga'] = harga\n",
    "#         properti['Lokasi'] = lokasi\n",
    "\n",
    "#         # Menambahkan dictionary properti ke list data_properti\n",
    "#         data_properti.append(properti)\n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "#     # Menyimpan data properti ke dalam file CSV\n",
    "#     header = ['K. Tidur', 'K. Mandi', 'L. Tanah', 'L. Bangunan', 'Tipe Properti', 'Sertifikat', 'Daya Listrik', 'ID Iklan', 'Harga', 'Lokasi']\n",
    "#     with open('data_properti.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "#         writer.writeheader()\n",
    "#         writer.writerows(data_properti)\n",
    "\n",
    "#     print('Web scraping selesai. Data properti telah disimpan dalam file data_properti.csv')\n",
    "# else:\n",
    "#     print('Gagal mengakses halaman dashboard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_properti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
